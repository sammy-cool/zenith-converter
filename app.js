const express = require("express");
const multer = require("multer");
const fs = require("fs-extra");
const path = require("path");
const AdmZip = require("adm-zip");
const winston = require("winston");
const PDFDocument = require("pdfkit");

// --- 1. CONFIGURATION & LOGGER ---
const app = express();
const upload = multer({ dest: "uploads/" });
app.use(express.json());

const logger = winston.createLogger({
  level: "info",
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.printf(
      ({ timestamp, level, message }) =>
        `[${timestamp}] ${level.toUpperCase()}: ${message}`,
    ),
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: "zenith.log" }),
  ],
});

// --- 2. GLOBAL STATE (Job Queue) ---
const jobs = {};

// --- 3. HELPER FUNCTIONS ---

/**
 * Cleanly extracts ZIP and returns the directory path
 */
function extractZip(zipPath, jobId) {
  const workDir = path.join(__dirname, "temp_extracted", jobId);
  const zip = new AdmZip(zipPath);
  zip.extractAllTo(workDir, true);
  return workDir;
}

/**
 * Scans directories recursively with Exclusion Logic
 */
function scanFiles(dir, workDir, exclusions) {
  let results = [];
  const list = fs.readdirSync(dir);

  for (const file of list) {
    const fullPath = path.join(dir, file);
    const relPath = path.relative(workDir, fullPath).replace(/\\/g, "/");

    // LOGIC: Check every path segment for banned folders
    const pathSegments = relPath.split("/");
    const isExcluded = pathSegments.some((seg) =>
      exclusions.folders.includes(seg),
    );

    if (isExcluded) continue;

    if (fs.statSync(fullPath).isDirectory()) {
      results = results.concat(scanFiles(fullPath, workDir, exclusions));
    } else {
      const ext = path.extname(file).toLowerCase();
      if (!exclusions.extensions.includes(ext)) {
        results.push(fullPath);
      }
    }
  }
  return results;
}

/**
 * Draws the "Dark Mode" Cover Page (User Experience)
 */
function drawCoverPage(doc, title) {
  doc.rect(0, 0, 600, 900).fill("#0d1117"); // GitHub Dark Background

  // Title
  doc
    .fillColor("#ffffff")
    .fontSize(28)
    .font("Helvetica-Bold")
    .text(title, 50, 300, { align: "center", width: 500 });

  // Metadata
  doc
    .fontSize(12)
    .font("Helvetica")
    .fillColor("#8b949e")
    .text("Generated by ansh.Priyanshu", 50, 360, { align: "center" })
    .text(new Date().toDateString(), 50, 380, { align: "center" });

  doc.addPage(); // Move to next page after cover
}

// --- 4. CORE ENGINE ---
async function processJob(jobId, zipPath, exclusions, originalName) {
  const workDir = path.join(__dirname, "temp_extracted", jobId);
  const pdfName = `${originalName}.pdf`;
  const finalPdfPath = path.join(__dirname, "public", pdfName);

  try {
    // A. Extraction
    jobs[jobId].message = "Extracting Files...";
    // We wrap this in setImmediate to allow the event loop one tick to update UI before freezing
    await new Promise((resolve) => setImmediate(resolve));
    extractZip(zipPath, jobId);

    // B. Scanning
    jobs[jobId].message = "Analyzing Project Structure...";
    const allFiles = scanFiles(workDir, workDir, exclusions);
    logger.info(
      `${originalName}: Job ${jobId}: Found ${allFiles.length} files to convert.`,
    );

    // C. PDF Setup
    const doc = new PDFDocument({
      autoFirstPage: false,
      bufferPages: true,
      margin: 40,
    });
    const writeStream = fs.createWriteStream(finalPdfPath);
    doc.pipe(writeStream);

    // Add Cover Page
    doc.addPage();
    drawCoverPage(doc, originalName);

    // D. Pre-Allocate Index Pages
    const requiredIndexPages = Math.ceil(allFiles.length / 35) + 1;
    jobs[jobId].message = "Reserving Index Pages...";
    for (let k = 0; k < requiredIndexPages; k++) doc.addPage();

    if (requiredIndexPages > 0) doc.addPage();

    // E. Render Content
    const tocEntries = [];

    for (let i = 0; i < allFiles.length; i++) {
      const filePath = allFiles[i];
      const relPath = path.relative(workDir, filePath).replace(/\\/g, "/");
      const safeId = `dest_${i}`;

      if (i > 0) doc.addPage();
      const currentPageNum = doc.bufferedPageRange().count;
      doc.addNamedDestination(safeId);
      tocEntries.push({ title: relPath, dest: safeId, page: currentPageNum });

      // File Header
      doc.rect(40, 40, 530, 25).fill("#e6f0ff").stroke();
      doc
        .fillColor("#0052cc")
        .fontSize(12)
        .font("Helvetica-Bold")
        .text(relPath, 50, 48);
      doc.moveDown(2);

      // File Content
      try {
        // Using await fs.readFile instead of readFileSync
        // This allows the server to answer /progress requests while reading!
        const buffer = await fs.readFile(filePath);

        const isBinary = buffer.slice(0, 1000).includes(0);

        if (isBinary) {
          doc
            .fillColor("#cc0000")
            .fontSize(10)
            .font("Helvetica-Oblique")
            .text("[Binary File Omitted]");
        } else {
          let content = buffer.toString("utf8").slice(0, 100000);
          content = content.replace(
            /[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]/g,
            "",
          );
          const lines = content.split(/\r?\n/);
          doc.fontSize(9).font("Courier");

          for (let j = 0; j < lines.length; j++) {
            const line = lines[j];
            const lineNum = (j + 1).toString();
            const rowHeight = Math.max(
              doc.heightOfString(line, { width: 480 }),
              12,
            );

            if (doc.y + rowHeight > doc.page.height - 50) doc.addPage();

            const currentY = doc.y;
            doc.rect(40, currentY, 35, rowHeight).fillColor("#f5f5f5").fill();
            doc
              .fillColor("#999999")
              .text(lineNum, 42, currentY + 2, { width: 30, align: "right" });
            doc
              .fillColor("#000000")
              .text(line, 85, currentY + 2, { width: 480, align: "left" });

            doc.x = 40;
          }
        }
      } catch (err) {}

      // Update UI Progress
      if (i % 10 === 0) {
        jobs[jobId].percent = Math.floor((i / allFiles.length) * 85);
        jobs[jobId].message = `Processing: ${path.basename(relPath)}`;
        // Allow Event Loop to process other requests (like SSE)
        await new Promise((resolve) => setImmediate(resolve));
        if (global.gc) global.gc();
      }
    }

    // F. Render Index
    jobs[jobId].message = "Writing Index...";
    let indexPageIndex = 1;
    doc.switchToPage(indexPageIndex);
    doc.y = 50;

    doc.rect(0, 0, 600, 800).fill("white");
    doc
      .fillColor("#000000")
      .fontSize(20)
      .font("Helvetica-Bold")
      .text("PROJECT INDEX", 50, 50, { align: "center" });
    doc.moveDown(2);
    doc.fontSize(10).font("Helvetica");

    for (const entry of tocEntries) {
      if (doc.y > 700) {
        indexPageIndex++;
        if (indexPageIndex <= requiredIndexPages) {
          doc.switchToPage(indexPageIndex);
          doc.rect(0, 0, 600, 800).fill("white");
          doc.y = 50;
        } else {
          doc.addPage();
          doc.y = 50;
        }
      }

      doc.fillColor("#0052cc").text(entry.title, {
        goTo: entry.dest,
        indent: 20,
        width: 450,
        continued: true,
        underline: true,
      });
      doc
        .fillColor("#000000")
        .text(entry.page.toString(), { align: "right", underline: false });
      doc.moveDown(0.5);
    }

    doc.end();
    await new Promise((resolve) => writeStream.on("finish", resolve));

    jobs[jobId].status = "completed";
    jobs[jobId].percent = 100;
    jobs[jobId].downloadUrl = `/${pdfName}`;
    jobs[jobId].message = "Ready to Download";
  } catch (error) {
    logger.error(`Job ${jobId} failed: ${error.message}`);
    jobs[jobId].status = "failed";
    jobs[jobId].message = "Error: " + error.message;
  } finally {
    try {
      if (await fs.pathExists(workDir)) await fs.remove(workDir);
      if (await fs.pathExists(zipPath)) await fs.unlink(zipPath);
    } catch (e) {}
  }
}

// --- 5. ROUTES ---
app.post("/convert", upload.single("zipfile"), (req, res) => {
  if (!req.file) return res.status(400).send("No file uploaded");

  const jobId = Date.now().toString();

  // Force clean filename from User Upload
  let cleanName = req.file.originalname
    .replace(/\.zip$/i, "")
    .replace(/[^a-zA-Z0-9_\-\.]/g, "_");
  if (!cleanName) cleanName = "Project_Export";

  let exclusions = { extensions: [], folders: [] };
  try {
    if (req.body.exclusions) exclusions = JSON.parse(req.body.exclusions);
  } catch (e) {}

  jobs[jobId] = { status: "processing", percent: 0, message: "Starting..." };
  res.json({ jobId });

  // Fire and forget
  processJob(jobId, req.file.path, exclusions, cleanName);
});

app.get("/progress/:jobId", (req, res) => {
  res.setHeader("Content-Type", "text/event-stream");
  res.setHeader("Cache-Control", "no-cache");
  res.setHeader("Connection", "keep-alive");

  const checkInterval = setInterval(() => {
    const job = jobs[req.params.jobId];
    if (job) {
      res.write(`data: ${JSON.stringify(job)}\n\n`);
      if (job.status === "completed" || job.status === "failed") {
        clearInterval(checkInterval);
        res.end();
        setTimeout(() => {
          if (jobs[req.params.jobId]) delete jobs[req.params.jobId];
        }, 600000);
      }
    }
  }, 500);
});

// It is intentional that the static files are served from the "public" directory after the "/" route
app.get("/", (req, res) => {
  res.sendFile(path.join(__dirname, "public", "index.html"));
  logger.info(
    `Home Page Requested - ${req.ip} ${req.method} ${req.url} ${req.headers["user-agent"]}`,
  );
});
app.use(express.static("public"));

app.get("/health", (req, res) => {
  const timestamp = new Date().toISOString();
  const additionalText = "Zenith is UP!";
  const responseText = `OK - ${timestamp} - ${additionalText}`;
  res.send(responseText);
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => logger.info(`Zenith V9 Enterprise running on ${PORT}`));
